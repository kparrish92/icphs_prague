\title{A simulated analysis of repeated measures in VOT: we need more tokens!}
\author{Kyle Parrish}
\organization{Rutgers University}
\email{kyle.parrish@rutgers.edu}


\maketitle

\begin{abstract}
In speech research, studies often make use of repeated measures, in which multiple tokens per condition are taken from the same participant and incorporate them into multilevel models. For instance, in VOT studies, researchers often elicit productions of stop consonants from multiple words produced by the same participant. It is unclear, however, how many repetitions of the same segment are necessary and how researchers go about choosing this number. The present study used reported data from previous literature to simulate an underlying distribution of 1000 points for each stop consonant (/p/, /t/, /k/, /b/, /d/, /g/) in order to determine how many of these tokens were necessary so that the random sample would be practically equivalent sample to the full simulated distribution.The results suggest that at least 15 tokens are necessary for all 6 stop consonants to achieve a practically equivalent sample (equivalence bounds d = +/- .4).
\end{abstract}

\keywords{Repeated Measures, VOT, simulation.}

